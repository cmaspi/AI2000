{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e105d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import category_encoders as ce\n",
    "\n",
    "def scale(a):\n",
    "    if(a<0):\n",
    "        a=-a\n",
    "    a/=np.power(10,np.floor(np.log10(a)))\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e387a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3427: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "test_df=pd.read_csv('test.csv')\n",
    "\n",
    "temp_train_df=train_df.drop(columns=['Fault'])\n",
    "temp_test_df=test_df.drop(columns=['Id'])\n",
    "\n",
    "total_df=pd.concat([temp_train_df,temp_test_df],ignore_index=True)\n",
    "\n",
    "# 'Report Number', 'Local Case Number', 'Person ID' are not useful\n",
    "total_df.drop(columns=['Agency Name','Driverless Vehicle','Road Name','Cross-Street Name','Report Number', 'Local Case Number', 'Person ID','Vehicle Model','Vehicle Make','Vehicle ID'],inplace=True)\n",
    "\n",
    "# dropping columns with to many NaN values\n",
    "total_df.dropna(axis=1,thresh=35000,inplace=True)\n",
    "\n",
    "# total_df['Agency Name'] = total_df['Agency Name'].str.replace(\"Montgomery County Police\",'MONTGOMERY')\n",
    "total_df['Driver Substance Abuse'] = total_df['Driver Substance Abuse'].str.replace(\"CONTRIBUTED\",'PRESENT')\n",
    "total_df['Driver Substance Abuse'] = total_df['Driver Substance Abuse'].str.replace(\"COMBINED SUBSTANCE\",'COMBINATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f88cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(total_total_df[''])\n",
    "# total_total_df[''].values_count(dropna=False)\n",
    "# total_total_df['']=total_total_df[''].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db940198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_df['Equipment Problems'].value_counts(dropna=False))\n",
    "total_df['Equipment Problems']=total_df['Equipment Problems'].fillna(value='NO MISUSE')\n",
    "# total_df['Equipment Problems']=total_df['Equipment Problems'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Parked Vehicle'].value_counts(dropna=False))\n",
    "# total_df['Parked Vehicle']=total_df['Parked Vehicle'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Vehicle Going Dir'].value_counts(dropna=False))\n",
    "total_df['Vehicle Going Dir']=total_df['Vehicle Going Dir'].fillna('Unknown')\n",
    "# total_df['Vehicle Going Dir']=total_df['Vehicle Going Dir'].astype('category').cat.codes\n",
    "\n",
    "total_df['Vehicle Continuing Dir']=total_df['Vehicle Continuing Dir'].fillna('Unknown')\n",
    "# total_df['Vehicle Continuing Dir']=total_df['Vehicle Continuing Dir'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Vehicle Movement'].value_counts(dropna=False))\n",
    "total_df['Vehicle Movement']=total_df['Vehicle Movement'].fillna(value='UNKNOWN')\n",
    "# total_df['Vehicle Movement']=total_df['Vehicle Movement'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Vehicle Body Type'].value_counts(dropna=False))\n",
    "total_df['Vehicle Body Type']=total_df['Vehicle Body Type'].fillna(value='PASSENGER CAR')\n",
    "# total_df['Vehicle Body Type']=total_df['Vehicle Body Type'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Vehicle Second Impact Location'].value_counts(dropna=False))\n",
    "total_df['Vehicle Second Impact Location']=total_df['Vehicle Second Impact Location'].fillna(value='TWELVE OCLOCK')\n",
    "# total_df['Vehicle Second Impact Location']=total_df['Vehicle Second Impact Location'].astype('category').cat.codes\n",
    "\n",
    "total_df['Vehicle First Impact Location']=total_df['Vehicle First Impact Location'].fillna(value='TWELVE OCLOCK')\n",
    "# total_df['Vehicle First Impact Location']=total_df['Vehicle First Impact Location'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Vehicle Damage Extent'].value_counts(dropna=False))\n",
    "total_df['Vehicle Damage Extent']=total_df['Vehicle Damage Extent'].fillna(value='DISABLING')\n",
    "# total_df['Vehicle Damage Extent']=total_df['Vehicle Damage Extent'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Drivers License State'].value_counts(dropna=False))\n",
    "total_df['Drivers License State']=total_df['Drivers License State'].fillna(value='MD')\n",
    "# total_df['Drivers License State']=total_df['Drivers License State'].astype('category').cat.codes\n",
    "\n",
    "# total_df['Injury Severity']=total_df['Injury Severity'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Driver Substance Abuse'].value_counts(dropna=False))\n",
    "total_df['Driver Substance Abuse']=total_df['Driver Substance Abuse'].fillna(value='UNKNOWN')\n",
    "# total_df['Driver Substance Abuse']=total_df['Driver Substance Abuse'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Traffic Control'].value_counts(dropna=False))\n",
    "total_df['Traffic Control']=total_df['Traffic Control'].fillna(value='UNKNOWN')\n",
    "# total_df['Traffic Control']=total_df['Traffic Control'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Light'].value_counts(dropna=False))\n",
    "total_df['Light']=total_df['Light'].fillna(value='UNKNOWN')\n",
    "# total_df['Light']=total_df['Light'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Surface Condition'].value_counts(dropna=False))\n",
    "total_df['Surface Condition']=total_df['Surface Condition'].fillna(value='UNKNOWN')\n",
    "# total_df['Surface Condition']=total_df['Surface Condition'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Weather'].value_counts(dropna=False))\n",
    "total_df['Weather']=total_df['Weather'].fillna(value='UNKNOWN')\n",
    "# total_df['Weather']=total_df['Weather'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Collision Type'].value_counts(dropna=False))\n",
    "total_df['Collision Type']=total_df['Collision Type'].fillna(value='SAME DIR REAR END')\n",
    "# total_df['Collision Type']=total_df['Collision Type'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Cross-Street Type'].value_counts(dropna=False))\n",
    "total_df['Cross-Street Type']=total_df['Cross-Street Type'].fillna(value='Unknown')\n",
    "# total_df['Cross-Street Type']=total_df['Cross-Street Type'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Route Type'].value_counts(dropna=False))\n",
    "total_df['Route Type']=total_df['Route Type'].fillna(value='Unknown')\n",
    "# total_df['Route Type']=total_df['Route Type'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['ACRS Report Type'].value_counts(dropna=False))\n",
    "# total_df['ACRS Report Type']=total_df['ACRS Report Type'].astype('category').cat.codes\n",
    "\n",
    "# print(total_df['Agency Name'].value_counts(dropna=False))\n",
    "# total_df['Agency Name']=total_df['Agency Name'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4f57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df['Location'].value_counts(dropna=False)\n",
    "total_df['Location']=total_df['Location'].str.replace(',',' ')\n",
    "\n",
    "split_data = total_df[\"Location\"].str.split(\" \")\n",
    "data = split_data.to_list()\n",
    "for i in range(len(total_df.index)):\n",
    "    data[i][1]=float(data[i][1])\n",
    "    data[i][0]=float(data[i][0])\n",
    "    data[i][1]=scale(data[i][1])\n",
    "\n",
    "names = [\"Location_1\",\"Location_2\"]\n",
    "\n",
    "temp_df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "total_df=total_df.drop(columns=['Location'])\n",
    "total_df=pd.concat([total_df,temp_df],axis=1)\n",
    "\n",
    "total_df['Crash Date/Time'] = pd.to_datetime(total_df['Crash Date/Time'])\n",
    "total_df['Hour'] = total_df['Crash Date/Time'].dt.hour\n",
    "total_df['day'] = total_df['Crash Date/Time'].dt.dayofweek\n",
    "total_df['year'] = total_df['Crash Date/Time'].dt.year\n",
    "total_df['month']=total_df['Crash Date/Time'].dt.month\n",
    "total_df.drop(columns=['Crash Date/Time'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5316710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmaspi/.local/lib/python3.9/site-packages/category_encoders/polynomial.py:216: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X.drop(col, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# one_hot = np.array(pd.get_dummies(total_df))\n",
    "base_learners = [\n",
    "                 ('rf_1', RandomForestClassifier(n_estimators=100, max_features='sqrt')),\n",
    "                 ('rf_2', LGBMClassifier(boosting_type='dart', drop_rate=0.5, max_drop=50, n_estimators=1000)),\n",
    "                 ('rf_3', XGBClassifier(use_label_encoder=False, learning_rate = 0.14, n_estimators=125, max_depth=8))\n",
    "                ]\n",
    "\n",
    "cl=[]\n",
    "for column in total_df.columns:\n",
    "    if total_df[column].dtype == object:\n",
    "        cl.append(column)\n",
    "encoder = ce.polynomial.PolynomialEncoder(verbose=False, cols=cl, drop_invariant=True)\n",
    "one_hot= encoder.fit_transform(total_df)\n",
    "\n",
    "clf = StackingClassifier(estimators=base_learners, n_jobs=12, final_estimator=LGBMClassifier(boosting_type='goss'))\n",
    "\n",
    "train_labels=np.array(train_df['Fault'])\n",
    "train_feas=one_hot[:51490]\n",
    "test_feas=one_hot[51490:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103f21fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf_1',\n",
       "                                RandomForestClassifier(max_features='sqrt')),\n",
       "                               ('rf_2',\n",
       "                                LGBMClassifier(boosting_type='dart',\n",
       "                                               drop_rate=0.5, max_drop=50,\n",
       "                                               n_estimators=1000)),\n",
       "                               ('rf_3',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance...\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=125, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              use_label_encoder=False,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None))],\n",
       "                   final_estimator=LGBMClassifier(boosting_type='goss'),\n",
       "                   n_jobs=12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_feas,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e859ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77235 entries, 0 to 77234\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Id      77235 non-null  int64\n",
      " 1   Fault   77235 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "predicn=clf.predict(test_feas)\n",
    "predicn=np.array(predicn, dtype=int)\n",
    "submsn = pd.DataFrame(predicn,columns=['Fault'])\n",
    "submsn=pd.concat([test_df['Id'],submsn],axis=1)\n",
    "\n",
    "submsn.to_csv('submsn.csv',index=False)\n",
    "submsn.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
